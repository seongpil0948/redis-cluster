"""
Redis í´ëŸ¬ìŠ¤í„° ê³µí†µ ì„¤ì • ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

ì´ ëª¨ë“ˆì€ main.pyì™€ polling_app.pyì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ”
ë…¸ë“œ ì„¤ì •, ì—°ê²° í•¨ìˆ˜, ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from typing import Literal, List, Optional
from redis.cluster import RedisCluster, ClusterNode
from redis.exceptions import RedisClusterException
import json

# í™˜ê²½ íƒ€ì… ì •ì˜
Environment = Literal["local", "dev", "prd"]

# í™˜ê²½ë³„ ë…¸ë“œ ì„¤ì •
CLUSTER_NODES = {
    "local": [ClusterNode("10.101.99.145", port) for port in range(7001, 7007)],
    "dev": [ClusterNode("10.101.91.145", port) for port in range(7001, 7007)],
    "prd": [
        ClusterNode("10.101.99.20", 6400),
        ClusterNode("10.101.99.20", 6401),
        ClusterNode("10.101.99.21", 6400),
        ClusterNode("10.101.99.21", 6401),
        ClusterNode("10.101.99.22", 6400),
        ClusterNode("10.101.99.22", 6401),
    ]
}

def get_cluster_nodes(env: Environment) -> List[ClusterNode]:
    """í™˜ê²½ì— ë”°ë¥¸ í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ëª©ë¡ ë°˜í™˜"""
    return CLUSTER_NODES[env]

def create_redis_cluster(env: Environment, **kwargs) -> RedisCluster:
    """
    Redis í´ëŸ¬ìŠ¤í„° ì—°ê²° ìƒì„±
    
    Args:
        env: í™˜ê²½ ('local', 'dev', 'prd')
        **kwargs: RedisClusterì— ì „ë‹¬í•  ì¶”ê°€ ë§¤ê°œë³€ìˆ˜
    
    Returns:
        RedisCluster: ì—°ê²°ëœ Redis í´ëŸ¬ìŠ¤í„° ê°ì²´
    
    Raises:
        RedisClusterException: ì—°ê²° ì‹¤íŒ¨ ì‹œ
    """
    nodes = get_cluster_nodes(env)
    
    # ê¸°ë³¸ ì„¤ì •
    default_config = {
        "startup_nodes": nodes,
        "decode_responses": True,
        "health_check_interval": 30,
        "socket_connect_timeout": 5,
        "socket_timeout": 5
    }
    
    # ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ë®ì–´ì“°ê¸°
    default_config.update(kwargs)
    
    return RedisCluster(**default_config)

def get_cluster_key_counts(rc: RedisCluster) -> int:
    """
    í´ëŸ¬ìŠ¤í„°ì˜ ì´ í‚¤ ê°œìˆ˜ë¥¼ ë°˜í™˜
    
    Args:
        rc: Redis í´ëŸ¬ìŠ¤í„° ê°ì²´
    
    Returns:
        int: ì´ í‚¤ ê°œìˆ˜
    """
    try:
        sizes = rc.dbsize(target_nodes=RedisCluster.PRIMARIES)
        if isinstance(sizes, dict):
            return sum(int(size) for size in sizes.values())
        elif isinstance(sizes, (list, tuple)):
            return sum(int(s) for s in sizes)
        else:
            return int(sizes)
    except Exception:
        return 0

def get_cluster_info(rc: RedisCluster) -> dict:
    """
    í´ëŸ¬ìŠ¤í„° ì •ë³´ ìˆ˜ì§‘
    
    Args:
        rc: Redis í´ëŸ¬ìŠ¤í„° ê°ì²´
    
    Returns:
        dict: í´ëŸ¬ìŠ¤í„° ì •ë³´ì™€ ë…¸ë“œ ì •ë³´
    """
    return {
        "info": rc.cluster_info(),
        "nodes": rc.cluster_nodes()
    }

def print_cluster_nodes(rc: RedisCluster, title: str = "Cluster nodes") -> None:
    """
    í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ëª©ë¡ì„ ì˜ˆì˜ê²Œ ì¶œë ¥
    
    Args:
        rc: Redis í´ëŸ¬ìŠ¤í„° ê°ì²´
        title: ì¶œë ¥ ì œëª©
    """
    print(f"ğŸ“ {title}:")
    for node in rc.get_nodes():
        print(f"   - {node.host}:{node.port}")

def test_connection(env: Environment, verbose: bool = True) -> Optional[RedisCluster]:
    """
    Redis í´ëŸ¬ìŠ¤í„° ì—°ê²° í…ŒìŠ¤íŠ¸
    
    Args:
        env: í™˜ê²½
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        RedisCluster: ì„±ê³µì‹œ ì—°ê²° ê°ì²´, ì‹¤íŒ¨ì‹œ None
    """
    try:
        if verbose:
            print(f"ğŸ”— Connecting to Redis cluster ({env} environment)...")
        
        rc = create_redis_cluster(env)
        rc.ping()
        
        if verbose:
            print("âœ… Connected successfully!")
            print_cluster_nodes(rc)
        
        return rc
        
    except RedisClusterException as e:
        if verbose:
            print(f"âŒ Connection failed: {e}")
        return None
    except Exception as e:
        if verbose:
            print(f"âŒ Unexpected error: {e}")
        return None

def cleanup_keys(rc: RedisCluster, keys: List[str], verbose: bool = True) -> int:
    """
    ì§€ì •ëœ í‚¤ë“¤ì„ ì‚­ì œ
    
    Args:
        rc: Redis í´ëŸ¬ìŠ¤í„° ê°ì²´
        keys: ì‚­ì œí•  í‚¤ ëª©ë¡
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        int: ì‚­ì œëœ í‚¤ ê°œìˆ˜
    """
    if verbose:
        print("Cleaning up keys...")
    
    deleted_count = 0
    for key in keys:
        try:
            if rc.delete(key):
                deleted_count += 1
        except Exception as e:
            if verbose:
                print(f"  âš ï¸  Failed to delete '{key}': {e}")
    
    if verbose:
        print(f"âœ… Cleaned up {deleted_count}/{len(keys)} keys")
    
    return deleted_count

def save_json_results(data: dict, filename_prefix: str, verbose: bool = True) -> str:
    """
    ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        data: ì €ì¥í•  ë°ì´í„°
        filename_prefix: íŒŒì¼ëª… ì ‘ë‘ì‚¬
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        str: ìƒì„±ëœ íŒŒì¼ëª…
    """
    from datetime import datetime
    
    timestamp = datetime.now().strftime("%m-%dT%H-%M")
    filename = f"{filename_prefix}_{timestamp}.json"
    
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        if verbose:
            print(f"ğŸ’¾ Results saved to {filename}")
        
        return filename
        
    except Exception as e:
        if verbose:
            print(f"âŒ Failed to save results: {e}")
        raise

def format_nodes_list(env: Environment) -> List[str]:
    """
    í™˜ê²½ì— ë”°ë¥¸ ë…¸ë“œ ëª©ë¡ì„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    
    Args:
        env: í™˜ê²½
    
    Returns:
        List[str]: "host:port" í˜•ì‹ì˜ ë…¸ë“œ ëª©ë¡
    """
    nodes = get_cluster_nodes(env)
    return [f"{node.host}:{node.port}" for node in nodes]

# ìƒìˆ˜ ì •ì˜
DEFAULT_TEST_KEYS = [
    "test:string",
    "test:hash", 
    "test:list",
    "test:set",
    "test:multi:key1",
    "test:multi:key2", 
    "test:multi:key3"
]

# í´ë§ í…ŒìŠ¤íŠ¸ìš© í‚¤ íŒ¨í„´
POLLING_KEY_PATTERNS = [
    "user:{user_id}:profile",
    "session:{session_id}:data", 
    "cache:{cache_id}:value",
    "counter:{counter_id}:count",
    "config:{config_id}:settings",
    "log:{log_id}:entry",
    "metric:{metric_id}:data",
    "temp:{temp_id}:storage"
]
